# 保险客户续保预测模型训练配置

# 训练设置
use_mlflow: true
best_model_metric: "roc_auc"  # 用于选择最佳模型的指标

# 模型配置
models:
  # 逻辑回归
  logistic_regression:
    enabled: true
    params:
      C: 1.0
      max_iter: 1000
      class_weight: "balanced"
      random_state: 42
      solver: "liblinear"
      penalty: "l2"
  
  # 随机森林
  random_forest:
    enabled: true
    params:
      n_estimators: 100
      max_depth: 10
      min_samples_split: 5
      min_samples_leaf: 2
      max_features: "sqrt"
      class_weight: "balanced"
      random_state: 42
      n_jobs: -1
  
  # 梯度提升树
  gradient_boosting:
    enabled: true
    params:
      n_estimators: 100
      learning_rate: 0.1
      max_depth: 5
      min_samples_split: 5
      min_samples_leaf: 2
      subsample: 0.8
      max_features: "sqrt"
      random_state: 42
  
  # XGBoost
  xgboost:
    enabled: true
    params:
      n_estimators: 100
      learning_rate: 0.1
      max_depth: 5
      subsample: 0.8
      colsample_bytree: 0.8
      min_child_weight: 1
      objective: "binary:logistic"
      eval_metric: "auc"
      random_state: 42
      n_jobs: -1
  
  # LightGBM
  lightgbm:
    enabled: true
    params:
      n_estimators: 100
      learning_rate: 0.1
      max_depth: 5
      num_leaves: 31
      subsample: 0.8
      colsample_bytree: 0.8
      min_child_weight: 1
      objective: "binary"
      class_weight: "balanced"
      random_state: 42
      n_jobs: -1

# 超参数优化设置
hyperparameter_search:
  method: "random"  # random 或 grid
  n_iter: 20  # 随机搜索的迭代次数
  cv: 5  # 交叉验证折数

# 超参数搜索空间
hyperparameters:
  # 逻辑回归
  logistic_regression:
    C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
    penalty: ["l1", "l2"]
    solver: ["liblinear"]
    class_weight: ["balanced", null]
  
  # 随机森林
  random_forest:
    n_estimators: [50, 100, 200, 300]
    max_depth: [5, 8, 10, 15, 20, null]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]
    max_features: ["sqrt", "log2", null]
    class_weight: ["balanced", "balanced_subsample", null]
  
  # 梯度提升树
  gradient_boosting:
    n_estimators: [50, 100, 150, 200]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    max_depth: [3, 5, 7, 9]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]
    subsample: [0.6, 0.8, 1.0]
    max_features: ["sqrt", "log2", null]
  
  # XGBoost
  xgboost:
    n_estimators: [50, 100, 200, 300]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    max_depth: [3, 5, 7, 9]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    min_child_weight: [1, 3, 5]
    gamma: [0, 0.1, 0.3, 0.5]
    reg_alpha: [0, 0.1, 1.0]
    reg_lambda: [0, 0.1, 1.0]
  
  # LightGBM
  lightgbm:
    n_estimators: [50, 100, 200, 300]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    max_depth: [3, 5, 7, 9]
    num_leaves: [15, 31, 63, 127]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    min_child_weight: [1, 3, 5]
    reg_alpha: [0, 0.1, 1.0]
    reg_lambda: [0, 0.1, 1.0] 